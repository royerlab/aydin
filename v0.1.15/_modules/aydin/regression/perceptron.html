<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>aydin.regression.perceptron &mdash; Aydin  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html">
            <img src="../../../_static/aydin_logo_grad_black_tr1.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/install.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/hardware_requirements.html">Hardware Requirements</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use Cases</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/basics.html">Denoising Basics with Aydin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/newyork.html">Noisy ‘New York’ Test Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/confocal_royer.html">Spinning-Disk Confocal Images of Zebrafish Embryos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/confocal_maitre.html">Spinning-Disk Confocal Microscopy Images of Mouse Embryos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/opencell.html">OpenCell Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../use_cases/pourquie.html">Chicken Embryos LSM 780 Images</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/tutorials_home.html">Tutorials Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/gui_tutorials.html">Aydin Studio (GUI) Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/cli_tutorials.html">Aydin CLI Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/api_tutorials.html">Aydin API Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/restoration.html">Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/image_translator.html">Image Translator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/transforms.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/feature_generator.html">Feature Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/regressors.html">Regressors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/io.html">IO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/nn.html">NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/options_json.html">Options JSON</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/example_images_gallery.html">Example Images Gallery</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contact Us</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contact_us/github.html">On Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contact_us/imagesc.html">On image.sc</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Aydin</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>aydin.regression.perceptron</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for aydin.regression.perceptron</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">join</span><span class="p">,</span> <span class="n">exists</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">psutil</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager.context</span> <span class="kn">import</span> <span class="n">device</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.optimizer_v2.adam</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.saving.model_config</span> <span class="kn">import</span> <span class="n">model_from_json</span>

<span class="kn">from</span> <span class="nn">aydin.io.folders</span> <span class="kn">import</span> <span class="n">get_temp_folder</span>
<span class="kn">from</span> <span class="nn">aydin.regression.nn_utils.callbacks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">NNCallback</span><span class="p">,</span>
    <span class="n">EarlyStopping</span><span class="p">,</span>
    <span class="n">ReduceLROnPlateau</span><span class="p">,</span>
    <span class="n">ModelCheckpoint</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">aydin.regression.nn_utils.models</span> <span class="kn">import</span> <span class="n">feed_forward</span>
<span class="kn">from</span> <span class="nn">aydin.regression.base</span> <span class="kn">import</span> <span class="n">RegressorBase</span>
<span class="kn">from</span> <span class="nn">aydin.util.log.log</span> <span class="kn">import</span> <span class="n">lsection</span><span class="p">,</span> <span class="n">lprint</span>
<span class="kn">from</span> <span class="nn">aydin.util.tf.device</span> <span class="kn">import</span> <span class="n">get_best_device_name</span>


<div class="viewcode-block" id="PerceptronRegressor"><a class="viewcode-back" href="../../../api/regressors/perceptron.html#aydin.regression.perceptron.PerceptronRegressor">[docs]</a><span class="k">class</span> <span class="nc">PerceptronRegressor</span><span class="p">(</span><span class="n">RegressorBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Perceptron Regressor uses a simple multi-layer perceptron neural</span>
<span class="sd">    network. The big disadvantage of neural-network regressors is that they</span>
<span class="sd">    are trained stochastically, which usually means that when your run them</span>
<span class="sd">    twice you also get two different results. In some cases there can be</span>
<span class="sd">    significant variance between runs which can be problematic when trying</span>
<span class="sd">    to compare results.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">device_max_mem</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">total</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
        <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        max_epochs : int</span>
<span class="sd">            Maximum number of epochs allowed</span>
<span class="sd">        learning_rate : float</span>
<span class="sd">            Learning rate</span>
<span class="sd">            (advanced)</span>
<span class="sd">        patience : int</span>
<span class="sd">            Number of epochs required for early stopping</span>
<span class="sd">            (advanced)</span>
<span class="sd">        depth : int</span>
<span class="sd">            Depth of the model</span>
<span class="sd">        loss : str</span>
<span class="sd">            Type of loss to be used</span>
<span class="sd">            (advanced)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;mae&#39;</span> <span class="k">if</span> <span class="n">loss</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;l1&#39;</span> <span class="k">else</span> <span class="n">loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;mse&#39;</span> <span class="k">if</span> <span class="n">loss</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;l2&#39;</span> <span class="k">else</span> <span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="k">with</span> <span class="n">lsection</span><span class="p">(</span><span class="s2">&quot;NN Regressor&quot;</span><span class="p">):</span>
            <span class="n">lprint</span><span class="p">(</span><span class="s2">&quot;with no arguments&quot;</span><span class="p">)</span>  <span class="c1"># TODO: fix these logs</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regressor_callback</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fits function y=f(x) given training pairs (x_train, y_train).</span>
<span class="sd">        Stops when performance stops improving on the test dataset: (x_test, y_test).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">lsection</span><span class="p">(</span><span class="s2">&quot;NN Regressor fitting:&quot;</span><span class="p">):</span>

            <span class="k">with</span> <span class="n">device</span><span class="p">(</span><span class="n">get_best_device_name</span><span class="p">()):</span>
                <span class="c1"># First we make sure that the arrays are of a type supported:</span>
                <span class="k">def</span> <span class="nf">assert_type</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
                        <span class="ow">or</span> <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                        <span class="ow">or</span> <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
                        <span class="ow">or</span> <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
                        <span class="ow">or</span> <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
                    <span class="p">)</span>

                <span class="c1"># Do we have a validation dataset?</span>
                <span class="n">has_valid_dataset</span> <span class="o">=</span> <span class="n">x_valid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_valid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

                <span class="n">assert_type</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
                <span class="n">assert_type</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">has_valid_dataset</span><span class="p">:</span>
                    <span class="n">assert_type</span><span class="p">(</span><span class="n">x_valid</span><span class="p">)</span>
                    <span class="n">assert_type</span><span class="p">(</span><span class="n">y_valid</span><span class="p">)</span>

                    <span class="c1"># Types have to be consistent between train and valid sets:</span>
                    <span class="k">assert</span> <span class="n">x_train</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">x_valid</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="k">assert</span> <span class="n">y_train</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">dtype</span>

                <span class="c1"># In case the y dtype does not match the x dtype, we rescale and cast y:</span>
                <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">integer</span><span class="p">)</span> <span class="ow">and</span> <span class="n">numpy</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span>
                    <span class="n">y_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">floating</span>
                <span class="p">):</span>

                    <span class="c1"># We remember the original type of y:</span>
                    <span class="n">original_y_dtype</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">dtype</span>

                    <span class="k">if</span> <span class="n">x_train</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
                        <span class="n">y_train</span> <span class="o">*=</span> <span class="mi">255</span>
                        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">has_valid_dataset</span><span class="p">:</span>
                            <span class="n">y_valid</span> <span class="o">*=</span> <span class="mi">255</span>
                            <span class="n">y_valid</span> <span class="o">=</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="n">original_y_scale</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">255.0</span>

                    <span class="k">elif</span> <span class="n">x_train</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint16</span><span class="p">:</span>
                        <span class="n">y_train</span> <span class="o">*=</span> <span class="mi">255</span> <span class="o">*</span> <span class="mi">255</span>
                        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">has_valid_dataset</span><span class="p">:</span>
                            <span class="n">y_valid</span> <span class="o">*=</span> <span class="mi">255</span> <span class="o">*</span> <span class="mi">255</span>
                            <span class="n">y_valid</span> <span class="o">=</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="n">original_y_scale</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mf">255.0</span> <span class="o">*</span> <span class="mf">255.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">original_y_dtype</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">original_y_scale</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># Get the number of entries and features from the array shape:</span>
                <span class="n">nb_data_points</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">num_features</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of data points : </span><span class="si">{</span><span class="n">nb_data_points</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">has_valid_dataset</span><span class="p">:</span>
                    <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of validation data points: </span><span class="si">{</span><span class="n">x_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of features per data point: </span><span class="si">{</span><span class="n">num_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Shapes of both x and y arrays:</span>
                <span class="n">x_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
                <span class="n">y_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Learning rate and decay:</span>
                <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
                <span class="n">learning_rate_decay</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning rate: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning rate decay: </span><span class="si">{</span><span class="n">learning_rate_decay</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Weight decay and noise:</span>
                <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
                <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight decay: </span><span class="si">{</span><span class="n">weight_decay</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added noise: </span><span class="si">{</span><span class="n">noise</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Initialise model if not done yet:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">feed_forward</span><span class="p">(</span>
                    <span class="n">num_features</span><span class="p">,</span>
                    <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">,</span>
                    <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
                    <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="n">learning_rate_decay</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of parameters in model: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Reshape arrays:</span>
                <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_shape</span><span class="p">)</span>
                <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_shape</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">x_valid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_valid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">x_valid</span> <span class="o">=</span> <span class="n">x_valid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_shape</span><span class="p">)</span>
                    <span class="n">y_valid</span> <span class="o">=</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_shape</span><span class="p">)</span>

                <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Keras batch size for training: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Effective number of epochs:</span>
                <span class="n">effective_number_of_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Effective max number of epochs: </span><span class="si">{</span><span class="n">effective_number_of_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Early stopping patience:</span>
                <span class="n">early_stopping_patience</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping patience: </span><span class="si">{</span><span class="n">early_stopping_patience</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Effective LR patience:</span>
                <span class="n">effective_lr_patience</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Effective LR patience: </span><span class="si">{</span><span class="n">effective_lr_patience</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Here is the list of callbacks:</span>
                <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="c1"># Set upstream callback:</span>
                <span class="n">keras_callback</span> <span class="o">=</span> <span class="n">NNCallback</span><span class="p">(</span><span class="n">regressor_callback</span><span class="p">)</span>

                <span class="c1"># Early stopping callback:</span>
                <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span>
                    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
                    <span class="n">min_delta</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="mf">0.000001</span><span class="p">,</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">),</span>
                    <span class="n">patience</span><span class="o">=</span><span class="n">early_stopping_patience</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Reduce LR on plateau:</span>
                <span class="n">reduce_learning_rate</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span>
                    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
                    <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">patience</span><span class="o">=</span><span class="n">effective_lr_patience</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                    <span class="n">min_lr</span><span class="o">=</span><span class="mf">0.0001</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">model_file_path</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span>
                    <span class="n">get_temp_folder</span><span class="p">(),</span>
                    <span class="sa">f</span><span class="s2">&quot;aydin_nn_keras_model_file_</span><span class="si">{</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1e16</span><span class="p">)</span><span class="si">}</span><span class="s2">.hdf5&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
                    <span class="n">model_file_path</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>

                <span class="c1"># Add callbacks to the list:</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">keras_callback</span><span class="p">)</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">)</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_learning_rate</span><span class="p">)</span>
                <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

                <span class="c1"># x_train = x_train.astype(numpy.float64)</span>
                <span class="c1"># y_train = y_train.astype(numpy.float64)</span>
                <span class="c1"># x_valid = x_valid.astype(numpy.float64)</span>
                <span class="c1"># y_valid = y_valid.astype(numpy.float64)</span>

                <span class="c1"># Training happens here:</span>
                <span class="k">with</span> <span class="n">lsection</span><span class="p">(</span><span class="s2">&quot;NN regressor fitting now:&quot;</span><span class="p">):</span>
                    <span class="n">train_history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                        <span class="n">x_train</span><span class="p">,</span>
                        <span class="n">y_train</span><span class="p">,</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
                        <span class="k">if</span> <span class="p">(</span><span class="n">x_valid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_valid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="n">effective_number_of_epochs</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">nb_data_points</span><span class="p">),</span>
                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># 0 if is_batch else 1,</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">lprint</span><span class="p">(</span><span class="s2">&quot;NN regressor fitting done.&quot;</span><span class="p">)</span>

                <span class="k">del</span> <span class="n">x_train</span>
                <span class="k">del</span> <span class="n">y_train</span>

                <span class="c1"># Reload the best weights:</span>
                <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">model_file_path</span><span class="p">):</span>
                    <span class="n">lprint</span><span class="p">(</span><span class="s2">&quot;Loading best model to date.&quot;</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">model_file_path</span><span class="p">)</span>

                <span class="c1"># loss_history = train_history.history[&#39;loss&#39;]</span>
                <span class="c1"># lprint(f&quot;Loss history after training: {loss_history}&quot;)</span>

                <span class="k">if</span> <span class="s1">&#39;val_loss&#39;</span> <span class="ow">in</span> <span class="n">train_history</span><span class="o">.</span><span class="n">history</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">last_val_loss</span> <span class="o">=</span> <span class="n">train_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

                <span class="n">loss_history</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="n">train_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="n">train_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span>
                <span class="p">}</span>

                <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

                <span class="k">return</span> <span class="n">_NNModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">original_y_dtype</span><span class="p">,</span> <span class="n">original_y_scale</span><span class="p">,</span> <span class="n">loss_history</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">_NNModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">original_y_dtype</span><span class="p">,</span> <span class="n">original_y_scale</span><span class="p">,</span> <span class="n">loss_history</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_y_dtype</span> <span class="o">=</span> <span class="n">original_y_dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_y_scale</span> <span class="o">=</span> <span class="n">original_y_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="n">loss_history</span>

    <span class="k">def</span> <span class="nf">_save_internals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># serialize model to JSON:</span>
            <span class="n">keras_model_file</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;keras_model.txt&#39;</span><span class="p">)</span>
            <span class="n">model_json</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">keras_model_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
                <span class="n">json_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">model_json</span><span class="p">)</span>

            <span class="c1"># serialize weights to HDF5:</span>
            <span class="n">keras_model_file</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;keras_weights.txt&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">keras_model_file</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load_internals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># load JSON and create model:</span>
        <span class="n">keras_model_file</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;keras_model.txt&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">keras_model_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
            <span class="n">loaded_model_json</span> <span class="o">=</span> <span class="n">json_file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_from_json</span><span class="p">(</span><span class="n">loaded_model_json</span><span class="p">)</span>
        <span class="c1"># load weights into new model:</span>
        <span class="n">keras_model_file</span> <span class="o">=</span> <span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;keras_weights.txt&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">keras_model_file</span><span class="p">)</span><span class="o">.</span><span class="n">expect_partial</span><span class="p">()</span>

    <span class="c1"># We exclude certain fields from saving:</span>
    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predicts y given x by applying the learned function f: y=f(x)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">lsection</span><span class="p">(</span><span class="s2">&quot;NN Regressor prediction:&quot;</span><span class="p">):</span>

            <span class="k">with</span> <span class="n">device</span><span class="p">(</span><span class="n">get_best_device_name</span><span class="p">()):</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of data points             : </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of features per data points: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Number of features:</span>
                <span class="n">num_of_features</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="c1"># We check that we get the right number of features.</span>
                <span class="c1"># If not, most likely the batch_dims are set wrong...</span>
                <span class="k">assert</span> <span class="n">num_of_features</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="c1"># How much memory is available in GPU:</span>
                <span class="n">max_gpu_mem_in_bytes</span> <span class="o">=</span> <span class="n">PerceptronRegressor</span><span class="o">.</span><span class="n">device_max_mem</span>

                <span class="c1"># We limit ourselves to using only a quarter of GPU memory:</span>
                <span class="n">max_number_of_floats</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_gpu_mem_in_bytes</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span> <span class="o">//</span> <span class="mi">4</span>

                <span class="c1"># Max size of batch:</span>
                <span class="n">max_gpu_batch_size</span> <span class="o">=</span> <span class="n">max_number_of_floats</span> <span class="o">/</span> <span class="n">num_of_features</span>

                <span class="c1"># Batch size taking all this into account:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">max_gpu_batch_size</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">256</span><span class="p">))</span>

                <span class="c1"># Heuristic threshold here obtained by inspecting batch size per GPU memory</span>
                <span class="c1"># Basically ensures ratio of 700000 batch size per 12GBs of GPU memory</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">700000</span> <span class="o">*</span> <span class="n">max_gpu_mem_in_bytes</span><span class="p">)</span> <span class="o">//</span> <span class="mi">12884901888</span>
                <span class="p">)</span>

                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicting. features shape = </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">lprint</span><span class="p">(</span><span class="s2">&quot;NN regressor predicting now...&quot;</span><span class="p">)</span>
                <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">lprint</span><span class="p">(</span><span class="s2">&quot;NN regressor predicting done!&quot;</span><span class="p">)</span>

                <span class="c1"># We cast back yp to the correct type and range:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_y_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">yp</span> <span class="o">=</span> <span class="n">yp</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">original_y_dtype</span><span class="p">)</span>
                    <span class="n">yp</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_y_scale</span>

                <span class="k">return</span> <span class="n">yp</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022. Chan Zuckerberg Biohub. All rights reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    : v0.1.15
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../../v0.1.11/index.html">v0.1.11</a></dd>
      <dd><a href="../../../../v0.1.12/index.html">v0.1.12</a></dd>
      <dd><a href="../../../../v0.1.13/index.html">v0.1.13</a></dd>
      <dd><a href="../../../../v0.1.14/index.html">v0.1.14</a></dd>
      <dd><a href="perceptron.html">v0.1.15</a></dd>
      <dd><a href="../../../../v0.1.8/index.html">v0.1.8</a></dd>
      <dd><a href="../../../../v0.1.9/index.html">v0.1.9</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #FFB366;
    }
    /* Sidebar */
<!--    .wy-nav-side {-->
<!--      background: #ff0000;-->
<!--    }-->
  </style>


</body>
</html>